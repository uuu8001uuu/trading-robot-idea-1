{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-odnbgFDtlzk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List\n",
    "import datetime\n",
    "import os\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_CkjbwcrSVqa"
   },
   "outputs": [],
   "source": [
    "# function calculate the execution time\n",
    "start_time = datetime.datetime.now()\n",
    "def execution_time_ml():\n",
    "  stop_time = datetime.now()\n",
    "  temp = stop_time-start_time\n",
    "  return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BA9C8fdGNMT1"
   },
   "outputs": [],
   "source": [
    "# pd.options.display.max_rows = None # show all rows when they are not visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1629360138333,
     "user": {
      "displayName": "Евгений Карнавалов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiVIHeY-DzC3t6Gh1C1_txQZM3y-tLor3oJsXq1ug=s64",
      "userId": "01524856507565613156"
     },
     "user_tz": -300
    },
    "id": "qwgRNovjNOE4",
    "outputId": "00b92501-9061-4c66-98a1-22166c153e8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# log into Google Disk for Google Colab/ if you use file on ssd on your computer, this code removes\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# set default folder for python\n",
    "import sys\n",
    "os.chdir('/content/drive/MyDrive/Colab Notebooks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCulyQyMrrZE"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_set.csv', index_col='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvOtXHH13rWZ"
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7nB4PBde3rWa"
   },
   "outputs": [],
   "source": [
    "# Column Date assign type datetime64[ns]\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "to_datetime_fmt = partial(pd.to_datetime, format='%Y-%M-%d')\n",
    "df['Date'] = df['Date'].apply(to_datetime_fmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1629360139421,
     "user": {
      "displayName": "Евгений Карнавалов",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiVIHeY-DzC3t6Gh1C1_txQZM3y-tLor3oJsXq1ug=s64",
      "userId": "01524856507565613156"
     },
     "user_tz": -300
    },
    "id": "fFB6AfMAzkyO",
    "outputId": "c08a064b-6632-42b9-c254-a5d711d414f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('1993-01-01 00:12:00'),\n",
       " Timestamp('2016-01-06 00:01:00'),\n",
       " Timestamp('2016-01-01 00:02:00'),\n",
       " Timestamp('2021-01-31 00:03:00'))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data into train and values\n",
    "train_size = int(df.shape[0] * 0.8)\n",
    "train_df = df.iloc[:train_size]\n",
    "val_df = df.iloc[train_size:]\n",
    "\n",
    "# show date start and end, on data train and values\n",
    "train_df[\"Date\"].min(), train_df[\"Date\"].max(), val_df[\"Date\"].min(), val_df[\"Date\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47WtlS5Gdn9O"
   },
   "outputs": [],
   "source": [
    "# Parameters model ML\n",
    "patience = 15\n",
    "# min_delta = 0.001\n",
    "shuffle = True\n",
    "use_scaler = True\n",
    "optimizer = 'adam'\n",
    "loss = 'mae'\n",
    "# dropout = 0.3\n",
    "# lstm = 200\n",
    "return_sequences = False\n",
    "activation = 'relu'\n",
    "dense_output = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWumyS1P1WOU"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df[[\"Close\"]])\n",
    "\n",
    "def make_dataset(\n",
    "    df,\n",
    "    window_size,\n",
    "    batch_size,\n",
    "    use_scaler=use_scaler,\n",
    "    shuffle=shuffle\n",
    "    ):\n",
    "  features = df[[\"Close\"]].iloc[:-window_size]\n",
    "  if use_scaler:\n",
    "    features = scaler.transform(features)\n",
    "  data = np.array(features, dtype=np.float32)\n",
    "  ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=df[\"Close\"].iloc[window_size:],\n",
    "      sequence_length=window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=shuffle,\n",
    "      batch_size=batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ydtm-GkZ7HRy"
   },
   "outputs": [],
   "source": [
    "# make compile and fit model ML\n",
    "def compile_and_fit(model, train_ds, val_ds, num_epochs, callbacks):\n",
    "  model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "      )\n",
    "  history = model.fit(\n",
    "      train_ds,\n",
    "      epochs=num_epochs,\n",
    "      validation_data=val_ds,\n",
    "      callbacks=callbacks,\n",
    "      verbose=1\n",
    "      )\n",
    "\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7XbkzUrABzO"
   },
   "outputs": [],
   "source": [
    "# make layers model ML\n",
    "def lstm_model(lstm, dropout, dense, use_load_model, directory_model):\n",
    "  if use_load_model == True: # you can use load model ML from file\n",
    "    model = tf.keras.models.load_model(directory_model) # you can use checpoint model for example training_step_1/cp-0024.ckpt\n",
    "  else:\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.LSTM(lstm, return_sequences=return_sequences),\n",
    "      tf.keras.layers.Dropout(dropout),\n",
    "      tf.keras.layers.Dense(dense, activation=activation, input_shape=[(len(train_df.columns)-2)]), # (len(train_df.columns)-2) calculate amount columns in train data_set\n",
    "      tf.keras.layers.Dropout(dropout),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(dense, activation=activation),\n",
    "      tf.keras.layers.Dropout(dropout),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(dense, activation=activation),\n",
    "      tf.keras.layers.Dropout(dropout),\n",
    "      tf.keras.layers.BatchNormalization(),\n",
    "      tf.keras.layers.Dense(dense_output),\n",
    "    ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6tnTGGxkaDX"
   },
   "outputs": [],
   "source": [
    "# function early stopping ML on overfitting\n",
    "def early_stopping_ml(min_delta):\n",
    "  early_stopping = callbacks.EarlyStopping(\n",
    "    patience=patience,\n",
    "    min_delta=min_delta,\n",
    "    restore_best_weights=True,\n",
    "  )\n",
    "  return early_stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lNsp_KYGpR2F"
   },
   "outputs": [],
   "source": [
    "# function saving ML results to a file\n",
    "from csv import writer\n",
    "import os\n",
    "def append_list_as_row(file_name, list_of_elem, header):\n",
    "    with open(file_name, 'a+', newline='') as write_obj:\n",
    "        list_of_elem.to_csv(write_obj, mode='a', header=header)\n",
    "        write_obj.close()\n",
    "\n",
    "def saving_results_ml(result, parametr_save):\n",
    "  if parametr_save == True:\n",
    "    if os.path.isfile('result1.csv') == True: # checking there is a file in the folder\n",
    "      append_list_as_row('result1.csv', result, header=False) # the parameters header enables or disables the output of the header in the file\n",
    "    else:\n",
    "      append_list_as_row('result1.csv', result, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuTqNJpisOmL"
   },
   "outputs": [],
   "source": [
    "# function saving full model ML to a file\n",
    "def saving_full_model(parametr_save, model_ml):\n",
    "  if parametr_save == True:\n",
    "    model_ml.save('best_model_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AmJgFQ4-0uwr"
   },
   "outputs": [],
   "source": [
    "def predict_calculate(lstm,\n",
    "                      dropout,\n",
    "                      dense,\n",
    "                      batch_size,\n",
    "                      min_delta,\n",
    "                      parametr_save,\n",
    "                      epochs,\n",
    "                      checkpoint_use,\n",
    "                      use_load_model,\n",
    "                      directory_model):\n",
    "  model_ml = lstm_model(lstm, dropout, dense, use_load_model, directory_model)    \n",
    "  window_size = batch_size + 2\n",
    "  \n",
    "  if checkpoint_use == True: # function use checpoint model (step by step) in training ML\n",
    "    checkpoint_path = \"training_step_2/cp-{epoch:04d}.ckpt\"\n",
    "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "    callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path, \n",
    "    verbose=1,\n",
    "    )\n",
    "  else:\n",
    "    callback = early_stopping_ml(min_delta) # function early stopping ML on overfitting\n",
    "  \n",
    "  train_ds = make_dataset(df=train_df,\n",
    "                          window_size=window_size,\n",
    "                          batch_size=batch_size,\n",
    "                          use_scaler=use_scaler,\n",
    "                          shuffle=shuffle)\n",
    "  val_ds = make_dataset(df=val_df,\n",
    "                        window_size=window_size,\n",
    "                        batch_size=batch_size,\n",
    "                        use_scaler=use_scaler,\n",
    "                        shuffle=shuffle)    \n",
    "  history =  compile_and_fit(model_ml, train_ds, val_ds, num_epochs=epochs, callbacks=callback)\n",
    "\n",
    "  history_df = pd.DataFrame(history.history)\n",
    "  history_df.loc[:, ['loss', 'val_loss']].plot()\n",
    "  print()\n",
    "  print(\"Minimum Loss: {:0.4f}\".format(history_df['loss'].min()))\n",
    "  print(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))\n",
    "  mae_train = model_ml.evaluate(train_ds)\n",
    "  mae_val = model_ml.evaluate(val_ds)\n",
    "  print()\n",
    "  print(\"MAE train_ds:\", mae_train)\n",
    "  print(\"MAE val_ds:\", mae_val, '\\n')\n",
    "\n",
    "  # function execution_time_ml() calculate the execution time code\n",
    "  temp = execution_time_ml()\n",
    "  print('Time to complete (h:m):', ':'.join(str(temp).split(':')[:2])) # show time in format h:m\n",
    "\n",
    "  # DataFrame creation with evaluation of results ML\n",
    "  result = pd.DataFrame({'Minimum_Loss': [history_df['loss'].min()],\n",
    "    'Minimum_Validation_Loss': [history_df['val_loss'].min()],\n",
    "    'MAE_train_ds': [mae_train],\n",
    "    'MAE_val_ds': [mae_val],\n",
    "    'Batch_size': [batch_size],\n",
    "    'Window_size': [window_size],\n",
    "    'Epochs': [epochs],\n",
    "    'Patience': [patience],\n",
    "    'Min_delta': [min_delta],                       \n",
    "    'Shuffle': [shuffle],\n",
    "    'Use_scaler': [use_scaler],\n",
    "    'Optimizer': [optimizer],\n",
    "    'Loss': [loss],\n",
    "    'Dropout': [dropout],\n",
    "    'LSTM': [lstm],\n",
    "    'Return_sequences': [return_sequences],\n",
    "    'Activation': [activation],\n",
    "    'Dense': [dense],\n",
    "    'Dense_output': [dense_output],\n",
    "    'Time_to_complete': [temp],\n",
    "    })\n",
    "  \n",
    "  saving_results_ml(result, parametr_save) # function saving ML results to a file\n",
    "\n",
    "  saving_full_model(parametr_save, model_ml) # function saving full model ML to a file\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ML_1_0.ipynb",
   "provenance": [
    {
     "file_id": "1L0P32Qd7Yt9WmHIos2fwBzBS7gPQFk7V",
     "timestamp": 1628659374482
    },
    {
     "file_id": "1lGCGxw7BCgdK6wvGzpZ7gsjt7b04NZb9",
     "timestamp": 1627452317580
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
